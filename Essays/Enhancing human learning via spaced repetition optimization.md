# Enhancing human learning via spaced repetition optimization

## 摘要

间隔重复是一种高效记忆的技术，它利用按照间隔重复算法确定的时间表反复复习内容，以提高长期保留率。然而，目前的间隔重复算法都是简单的基于规则的启发式算法，只有一些硬编码的参数。在这里，我们利用标记时间点过程的框架，引入了一种灵活的间隔重复的表示方法，然后把具有可证明保证的间隔重复算法设计作为一个带跳的随机微分方程的最优控制问题来解决。对于两个著名的人类记忆模型，我们表明，如果学习者的目标是在复习频率上付出代价的前提下，使待学内容的回忆概率最大化，那么最优的复习计划是由回忆概率本身给出的。因此，我们就可以开发出一种简单的、可扩展的在线间隔重复算法MEMORIZE来确定最佳复习时间。我们利用流行的语言学习在线平台Duolingo的数据进行了大规模的自然实验，结果表明，遵循我们算法确定的复习时间表的学习者比遵循由几种启发式方法确定的替代时间表的学习者记忆效率更高。

## 引言

我们记住一条信息的能力关键取决于我们复习的次数、复习的时间分布以及自上次复习以来的时间，正如Ebbinghaus(1)的一项开创性研究所表明的那样。这两个因素的影响在实验心理学文献（2，3）中得到了广泛的研究，特别是在第二语言习得研究中（4-7）。此外，这些实证研究还促使人们使用闪卡，即学习者按照由间隔重复算法确定的时间表反复复习的小块信息(8)，其目标是确保学习者花更多(更少)的时间来处理遗忘(回忆)的信息。

设计间隔重复算法的任务具有丰富的历史，从Leitner系统开始（9）。最近，有几项工作(10，11)提出了一些启发式算法，这些算法在学习者即将忘记一个项目时安排复习，即当选择的记忆模型(1，12)给出的回忆概率下降到一个阈值以下时。一个正交的研究路线(7，13)通过确定在固定的复习时间内，哪个项目从复习中获益最大，来追求局部最优的时间安排。在此过程中，研究者还提出了启发式算法，通过贪婪地选择最接近其最大学习率的项目来决定复习哪个项目。

近年来，间隔重复软件和 Mnemosyne、Synap、Duolingo 等在线平台越来越受欢迎，往往取代了实体闪卡的使用。这些软件和在线平台的承诺是，自动化的精细监测和更大程度的控制将产生更有效的间隔重复算法。然而，上述大多数的间隔重复算法都是简单的基于规则的启发式算法，只有一些硬编码的参数(8)，无法实现这一承诺——自适应的、数据驱动的、具有可证明的保证的算法直到最近才被发现(14，15)。在这些最近的显著例外中，与我们的工作最密切相关的是Reddy等人(15)，他们为一种特殊的间隔重复方法--用于复习闪卡的Leitner系统(9)提出了一个排队网络模型，然后开发了一种用于调度复习的启发式近似算法。然而，他们的启发式并不具有可证明的保证，它不能适应学习者在一段时间内的表现，而且它是专门为Leitner系统设计的。

在这项工作中，我们开发了一个计算框架，以推导出最佳的间隔重复算法，专门设计以适应学习者的表现，正如现代间隔重复软件和在线学习平台所持续监测的那样。更具体地说，我们首先介绍了使用标记时间点过程框架对间隔重复的灵活表示（16）。对于几个著名的人类记忆模型（1，12，17-19），我们用这种表述方式，通过一组带跳的随机微分方程（SDE）来表达学习者对所学内容的遗忘率和回忆概率的动态变化。然后，我们可以通过求解带跳的SDE的随机最优控制问题（20-23），找到间隔重复的最优复习计划。在此过程中，我们需要引入一种证明技术，以找到所谓的 Hamilton-Jacobi-Bellman(HJB) 方程(SI附录，第3和第4节)的解，这是独立的兴趣。

对于两个著名的记忆模型，我们表明，如果是学习者的目标是在复习频率上付出代价的前提下，使待学内容的回忆概率最大化，该解决方案发现了最佳复习速度或复习强度与待学内容的回忆概率之间的线性关系，其斜率为负。因此，我们可以开发出一种简单的、可扩展的在线间隔重复算法，我们将其命名为 MEMORIZE，以确定最佳复习次数。最后，我们利用流行的语言学习在线平台Duolingo的数据进行了大规模的自然实验，结果表明，遵循我们算法确定的复习时间安排的学习者比遵循由几种启发式方法确定的替代时间安排的学习者记忆效果更好。为了促进这一领域的研究，我们将发布我们算法的开源实现（24）。

## 间隔重复的建模框架

我们的框架对记忆模型的特殊选择是不可知的——它提供了一套技术来寻找记忆模型下最优的复习计划。在这里，为了便于阐述，我们展示了我们的框架，用于心理学文献中一个著名的记忆模型，即二元回忆的指数遗忘曲线模型(1，17)，并使用(一个变体)最近的机器学习方法，半衰期回归(25)来估计复习对这种模型参数的影响。在SI附录第6和第7节中，我们将我们的框架应用于其他两个流行的记忆模型，即幂律遗忘曲线模型（18，19）和多尺度上下文模型（MCM）（12）] 。

更具体地说，给定一个学习者要用间隔重复的方法记忆一组项目I，即对项目进行重复的、间隔的复习，我们将每个复习事件表示为三元组，

![image-20210309164846311](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210309164846311.png)

这意味着学习者在时间 t 复习了项目i∈I，并且或者回忆了它（r=1），或者忘记了它（r=0）。这里要注意的是，每个复习事件都包括测试的结果（即回忆），因为在大多数间隔复习软件和在线平台（如Mnemosyne、Synap和Duolingo）中，按照Reidiger和Karpicke（26）的开创性工作，学习者在每次复习中都要接受测试。

给定上述表示方法，我们用指数遗忘曲线模型来模拟学习者在时间 t 回忆（遗忘）第 i 项的概率；即：

![image-20210310110115519](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210310110115519.png)

其中，$t_r$ 为最后一次复习的时间，$n_{i}(t) \in \mathbb{R}^{+}$为时间 t 的遗忘率，该遗忘率可能取决于很多因素，例如，项目难度和/或之前（未）成功回忆该项目的次数。[以前的工作经常使用遗忘率的倒数，称为记忆强度或半衰期，$s(t)=n^{-1}(t)$(15,25)。然而，对我们来说，用遗忘率来工作更容易理解]。然后，我们用一个多维计数过程$N(t)$来跟踪复习次数，其中第i个条目$N_i(t)$统计学习者在时间t之前复习项目 i 的次数，按照时间点过程的文献(16)，我们用它们对应的强度u(t)，即$\mathbb{E}[d \boldsymbol{N}(t)]=\boldsymbol{u}(t) d t$来表征这些计数过程，并把回忆率 r 看作它们的二进制标记。此外，每当学习者复习一个项目时，回忆率r已经被实验证明对项目的遗忘率有影响（3，15，25）。在这里，我们用半衰期回归（25）来估计这样的效应，它隐含地假设在复习过程中对项目i的召回对遗忘率$n_{i}(t)$有乘法效应--在时间tr成功的召回会使遗忘率改变$(1-\alpha_{i})$，即$n_{i}(t)=\left(1-\alpha_{i}\right) n_{i}\left(t_{r}\right), \alpha_{i} \leq 1$，而不成功的召回会使遗忘率改变$(1+\beta_{i})$，即$n_{i}(t)=\left(1+\beta_{i}\right) n_{i}\left(t_{r}\right), \beta_{i} \geq 0$。其中，初始遗忘率$n_{i}(0)$反映了项目的难度，较难的项目与较容易的项目相比，初始遗忘率较高，参数$\alpha_{i}$，$\beta_{i}$ 和$n_{i}(0)$采用真实数据估计(详见SI附录第8节)。

在我们继续深入研究之前，我们承认，一些实验室研究（6，27）已经提供了经验证据，证明保留率遵循一个倒U形，即大量练习并不能提高遗忘率——如果复习时一个项目在学习者的短期记忆中，那么长期保留率就不会提高。因此，我们可以主张在我们的框架中采用时间变化的参数$\alpha_{i}(t)$和$\beta_{i}(t)$。然而，有几个原因使我们不能这样做。(i)在时变参数下的最优复习计划的推导变得非常具有挑战性；(ii)对于我们Duolingo数据集中的复习序列，在我们的建模框架中允许时变的$\alpha_{i}$和$\beta_{i}$并不能带来更准确的召回预测(SI附录，第9节)；(iii)几个流行的间隔重复启发式方法，如具有指数间隔的Leitner系统和SuperMemo，尽管隐含地假设$\alpha_{i}$和$\beta_{i}$不变，但在实践中取得了合理的成功。指数间隔的Leitner系统可以用我们的公式明确地投出，对所有项目都有特定的$\alpha_{i}$和$\beta_{i}$的选择，并且初始遗忘率$n_{i}(0)=n(0)$相同(SI附录，第11节)]。也就是说，在未来的工作中，推导出时变参数下的最优复习计划将是一个有趣的领域。

接下来，我们将遗忘率$n_{i}(t)$的动态变化和使用带跳的SDEs对每个项目i∈I的召回概率$m_{i}(t)$。这对于我们使用随机最优控制的间隔重复算法的设计非常有用。更具体地说，遗忘率$n_{i}(t)$的动态很容易由以下公式给出

![image-20210309164954977](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210309164954977.png)

其中$N_i(t)$是相应的计数过程，$r_i(t)\in\{0,1\}$表示第i项是否在时间t被成功召回，类似地，召回概率$m_i(t)$的动态由命题1给出(在SI附录第1节中证明)。

命题1. 给定一个具有复习强度$u_i(t)$的项目i∈I，由式1定义的召回概率$m_i(t)$是一个马尔可夫过程，其动态可以由以下带跳的SDE来定义

![image-20210309165201263](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210309165201263.png)

其中$N_i(t)$是与复习强度$u_i(t)†$相关的计数过程。

最后，给定一组项目I，我们将间隔重复算法的设计投向寻找最优的项目复习强度$\boldsymbol{u}(t)=\left[u_{i}(t)\right]_{i \in \mathcal{I}}$，使项目的回忆概率的特定(凸)损失函数$\ell(\boldsymbol{m}(t), \boldsymbol{n}(t), \boldsymbol{u}(t))$的期望值最小化，$\boldsymbol{m}(t)=\left[m_{i}(t)\right] i \in \mathcal{I}$。遗忘率，$\boldsymbol{n}(t)=\left[n_{i}(t)\right] i \in \mathcal{I}$；以及强度本身，$\boldsymbol{u}(t)$；在一个时间窗口$(t_0,t_f]$；

![image-20210309170150760](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210309170150760.png)

其中，$\boldsymbol{u}(t_0,t_f]$表示从$t_0$到$t_f$的项目复习强度，期望值取于所有可能实现的相关计数过程和(项目)召回，损失函数相对于召回概率(遗忘率和强度)为非递增(非递减)，因此，它在限制项目复习次数的同时，奖励持久的学习，$\phi\left(\boldsymbol{m}\left(t_{f}\right), \boldsymbol{n}\left(t_{f}\right)\right)$是一个任意的惩罚函数。[惩罚函数$\phi\left(\boldsymbol{m}\left(t_{f}\right), \boldsymbol{n}\left(t_{f}\right)\right)$是推导最优复习强度$u^∗(t)$的必要条件]。在这里，请注意，由式2和式3定义的遗忘率n(t)和召回概率m(t)取决于我们旨在优化的复习强度$\boldsymbol{u}(t)$，因为$\mathbb{E}[d \boldsymbol{N}(t)]=\boldsymbol{u}(t) d t$。

## MEMORIZE 算法 

由式4定义的间隔重复问题，可以从带跳的SDE的随机最优控制的角度来解决(20)。在这里，我们首先推导出只考虑一个项的问题的解决方案，提供该解决方案的有效实际实现，然后将其推广到多个项的情况。

给定一个项目i，我们可以写出间隔重复问题。即式4，对于它与复习强度$u_i(t)=u(t)$和相关计数过程$N_i(t)=N(t)$，回忆结果$r_i(t)=r(t)$，回忆概率$m_i(t)=m(t)$，遗忘率$n_i(t)=n(t)$。进一步，利用式2和式3，我们可以通过以下两个耦合跳变SDE来定义遗忘率n(t)和召回概率m(t)：

![image-20210309165435841](C:%5CUsers%5CL.M.Sherlock%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210309165435841.png)

初始条件为$n(t_0)=n_0$，$m(t_0)=m_0$。

接下来，我们为上述问题定义了一个最优的代价函数J，利用Bellman最优原理推导出相应的HJB方程（28），并利用HJB方程的独特结构找到问题的最优解。

定义2：最优代价函数$J(m(t), n(t), t)$定义为在时间 t 从状态$(m(t),n(t))$到时间$t_f$的最终状态的成本的最小值：

![image-20210309170125870](C:%5CUsers%5CL.M.Sherlock%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210309170125870.png)

现在，我们利用上述定义所允许的Bellman最优原则，将问题分解成更小的子问题。利用回忆概率$m(t)$和遗忘率$n(t)$的马尔科夫特性，很容易得出Bellman的最优原则]。由于$d J(m(t), n(t), t)=J(m(t+d t), n(t+d t), t + d t)-J(m(t),n(t),t)$，因此，我们可以，将式5改写为

![image-20210309170225228](C:%5CUsers%5CL.M.Sherlock%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210309170225228.png)

然后，为了推导出HJB方程，我们用SI附录第2节，Lemma 1来微分J关于时间t、m(t)和n(t)：

![image-20210309170302530](C:%5CUsers%5CL.M.Sherlock%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210309170302530.png)

为了解决上述方程，我们需要定义损失 。根据随机最优控制的文献(28)，我们考虑以下二次方程形式，它与召回概率(强度)的关系是不增(不减)的，所以它在奖励学习的同时，也限制了项目复习的数量。

![image-20210309170344461](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210309170344461.png)

其中 q 是一个给定的参数，它对召回概率和项目复习数进行了权衡——其值越高，复习数越低。需要注意的是，这种特殊的损失函数的选择并不直接对复习数进行硬性约束，而是通过惩罚高复习强度来限制复习数。(给定一个理想的实践水平，参数 q 的值可以很容易地通过模拟找到，因为平均复习数相对于 q 是单调下降的)。

在这些定义下，我们可以通过取式7中相对于u(t)的导数，找到最优强度和最优成本之间的关系。

![image-20210309183545036](C:%5CUsers%5CL.M.Sherlock%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210309183545036.png)

最后，我们将上述方程插入到式7中，发现最优成本 J 需要满足以下非线性微分方程。

![image-20210309183608760](C:%5CUsers%5CL.M.Sherlock%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20210309183608760.png)

为了继续走得更远，我们依靠一个技术性的定理（SI附录，第3节，Lemma 2），推导出一个参数化的损失系列的最优成本 J 。利用SI附录，第3节，Lemma 2，最优复习强度很容易由定理3给出（在SI附录，第4节证明）。

定理3. 给定单个项目，在平方损失下，由式4定义的间隔重复问题的最优复习强度，由式8定义，给出的是

![image-20210309183653173](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210309183653173.png)

请注意，最优强度只取决于召回概率，其动态由式2和式3给出，因此可以用一个非常有效的程序来采样复习时间，我们将其命名为MEMORIZE。算法1提供了MEMORIZE的一个伪代码实现。在算法中，$Sample(u(t))$从一个强度为u(t)的非齐次泊松过程中采样，它返回采样时间，$ReviewItem(t)$返回一个项目在时间t的回忆结果r，其中r=1表示项目被成功回忆，r=0表示没有被回忆。此外，请注意，$t$表示一个(时间)参数，$s$和$t'$表示具体的(时间)值，我们使用标准的稀疏算法(29)从一个非齐次泊松过程中采样。[在一些实际部署中，人们可能希望对最优强度u(t)进行离散化，例如，"在每个小时的顶部，决定是否进行复查"]。

![image-20210310135942263](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210310135942263.png)

给定一组具有复习强度的多个项目I的复习强度$u(t)$以及相关的计数过程$N(t)$、召回结果$r(t)$、召回概率$m(t)$和遗忘率$n(t)$，我们可以解决由式4定义的间隔重复问题，类似于单项的情况。更具体地说，考虑以下损失的二次形式 。

![image-20210310102457202](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210310102457202.png)

其中$\left\{q_{i}\right\}_{i \in \mathcal{I}}$是给定的参数，这些参数权衡了召回概率和项目复习次数，可能会偏重于一个项目的学习，而不是另一个项目的学习。然后，可以利用项目之间的独立性假设，得出每个项目的最优复习强度，其过程与单项目的情况类似。

定理4。给定一组项目I，在二次损失下，由式4定义的间隔重复问题中，每个项目i∈I的最优复习强度由以下公式给出。

![image-20210310102626432](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210310102626432.png)

最后，请注意，我们只需运行|I|实例的memorize，每个项目一个，就可以很容易地对项目复习时间进行采样。

## 实验设计

我们使用从流行的语言学习在线平台Duolingo收集的数据（数据集可在https://github.com/duolingo/halflife-regression）来验证我们的算法MEMORIZE。参考SI附录，第5节，使用合成数据对我们的算法进行实验验证，其目标是在受控环境下使用我们无法在真实数据中计算的指标和基线对其进行分析）。这个数据集包括∼1200万个研究会话，涉及∼530万个唯一的(用户，词)对，我们用D表示，收集的时间为2周。在一个会话中，一个用户回答多个问题，每个问题包含多个单词。关于Duolingo数据集的更多细节，请参考SI附录，第12节）。每个单词都映射到一个项目i，会话中包含单词i的句子的正确召回率被用作其召回概率的经验估计。$\hat{m}(t)$在会话t时，与前人的工作(25)一样。如果一个词在一个会话中被完美地召回，则认为是成功的召回，即$r_i (t)=1$，否则认为是不成功的召回，即$r_i (t)=0$.由于我们可以期望模型参数的估计只对具有足够数量的复习事件的用户和项目是准确的，所以我们只考虑具有至少30次复习事件的用户和至少被复习了30次的词。经过这个预处理步骤后，我们的数据集由520万对独特的（用户、词）组成。

我们将我们的方法与两条基线进行比较。(一)统一复习计划，以恒定的速度 $\mu$ 发送项目进行复习，(二)基于阈值的复习计划，在时间s，当一个项目的回忆概率达到阈值$m^{th}$时，将其复习强度增加$c \exp ((t-s) / \zeta)$。阈值基线类似于之前工作提出的启发式方法（10，11，30），它在学习者即将忘记一个项目时安排复习。我们不与Reddy等人(15)提出的算法进行比较，因为它是专门为莱特纳系统设计的，它假设了一组离散的遗忘率值，因此，不适用于我们(更一般的)环境。虽然我们不能进行实际的干预来评估每种方法的性能，下面的见解可以进行大规模的自然实验。Duolingo使用手工调整的间隔重复算法，向用户建议复习时间；然而，用户往往不会完全在建议的时间进行复习，因此，一些（用户、项目）对的时间表会比阈值或memorize更接近统一，反之亦然，如图1所示。

![image-20210310140627180](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210310140627180.png)

> 图1. 在MEMORIZE（顶部）、基于阈值的复习计划（中间）和统一复习计划（底部）下，对应的复习时间具有高似然性的（用户，项目）对的例子。在每张图中，每个烛台对应一个复习事件，如果召回成功（不成功），则绿色圆圈（红色交叉），时间t =0对应用户第一次接触我们数据集中的项目，可能对应也可能不对应第一次复习事件。其复习时间更紧密跟随memorize或基于阈值的时间表的对子倾向于在每次回忆成功时增加复习的时间间隔，而相反，统一的复习时间表则不会。MEMORIZE比基于阈值的时间表更倾向于间隔复习，以较少的努力实现相同的回忆模式。

因此，我们能够将每个 (user, item) 对分配到实验组（即memorize）或对照组（即uniform或阈值）。更详细的说，我们利用这一洞察力设计了一个稳健的评估程序，该程序依赖于（i）似然比较来确定用户在所有复习过程中（除了复习序列中的最后一个），即$e_{1}, \ldots, e_{n-1}$，以及(ii)质量度量，经验遗忘率。$\hat{n}$，它可以只使用每个复习序列的最后一次复习$e_n$（和保留区间$t_{n-1}-t_{1}$）来估计，并且不依赖于记忆模型的特定选择。关于我们的评估程序的更多细节，请参考材料和方法。[注意，我们的目标是评估不同的复习时间表对复习的间隔有多大影响——我们的目标不是评估基础记忆模型的预测能力；我们是依靠以前的工作来实现的（18，25）。然而，为了完整起见，我们在SI附录第8节中提供了一系列我们在这项工作中使用的记忆模型的基准和评估】。]

## 结果

首先，我们按照复习次数n和训练周期（即$t_{n-1}-t_{1}$）对（用户、项目）对进行分组。然后，对于每个召回模式，我们创建实验组（memorize）和对照组（均匀组和阈值组），对于每个组中的每个回忆序列，计算其经验遗忘率。图2总结了自观察窗口开始以来，对三个不同训练期的多达7个复习序列的结果。结果表明，相对于基于统一和阈值的基线，MEMORIZE提供了竞争优势，并且随着训练期的增加，MEMORIZE取得最大竞争优势的复习次数也在增加。在这里，我们可以排除这种优势是由于项目难度造成的选择偏差的结果（SI附录，第13节）。

![image-20210310140730759](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210310140730759.png)

> 图2. (A-C)对于不同复习次数n和不同训练周期$T=t_{n-1}-t_{1}$的序列，MEMORIZE、统一复习计划和基于阈值的复习计划的前25%对的平均经验遗忘率，以似然为单位。方框表示25%和75%的分位数，实线表示中值，数值越低表示性能越好。MEMORIZE相对于统一基线和基于阈值的基线提供了竞争优势，随着训练期的增加，MEMORIZE取得最大竞争优势的复习次数也在增加。对于每个不同的复习次数和训练期，∗表示MEMORIZE与阈值和MEMORIZE与统一调度之间存在统计学上的显著差异（Mann-Whitney U检验；P值<0.05）。

接下来，我们再进一步验证，只要特定的学习者紧跟 memorize，她的表现就会更优秀。更具体地说，对于每个学习者至少有70个复习序列，训练周期T=8±3.2 d，我们选择MEMORIZE下对数似然的前50%和后50%的复习序列，计算经验遗忘率和对数似然值之间的皮尔逊相关系数。图3总结了结果，结果显示，平均而言，用户只要更紧密地跟随memorize，就能获得更低的经验遗忘率。

![image-20210310140359642](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210310140359642.png)

> MEMORIZE 下学习者复习序列的上下50%的对数似然率与其相关经验遗忘率之间的皮尔逊相关系数。圆圈表示中值，条形表示标准误差。较低的相关值对应着memorize带来的更大收益。为了保证估算的可靠性，我们考虑了至少有70个复习序列的学习者，训练时间T=8±3.2 d，其中有322个这样的学习者。

自莱特纳系统(9)以来，已经有大量的间隔重复算法（7，8，10，11，13）。然而，关于设计具有可证明保证的自适应数据驱动的间隔重复算法的工作还很少。在这项工作中，我们引入了一个原则性的建模框架来设计具有可证明保证的在线间隔重复算法，这些算法是专门为适应学习者的表现而设计的，由现代间隔重复软件和在线平台监测。我们的建模框架用标记时间点过程和带跳的SDE的框架来表示间隔重复，并利用这种表示方式，将间隔重复算法的设计抛出为这种带跳SDE的随机最优控制问题。由于我们的框架对特定的建模选择，即记忆模型和二次损失函数是不可知的，我们相信它提供了一个强大的工具来寻找在给定的记忆模型和损失的选择下证明是最优的间隔重复算法。

未来的工作有很多有趣的方向。例如，进行大规模的干预实验来评估我们的算法与Duolingo等部署的现有间隔重复算法的性能比较将是有趣的。此外，在我们的工作中，我们考虑了一个特定的二次方损失和对复习事件数量的软约束；然而，对于其他捕捉特定学习目标的损失和对事件数量的硬约束，推导出最佳复习强度将是有用的。我们假设，通过复习一个项目，只能影响其回忆概率和遗忘率。然而，项目可能是依赖性的，通过回忆一个项目，可以影响多个项目的回忆概率和遗忘率。我们使用的数据集仅跨度为2周，这就限制了我们可以研究的复习和保留时间间隔的范围。在跨度更长的时间段的数据集中评估我们的框架将是非常有趣的。最后，我们相信，支撑我们算法的数学技术，即带跳的SDE的随机最优控制，有可能在广泛的应用中推动控制算法的设计。

## 材料与方法

### 评估程序

为了评估我们提出的算法的性能，我们依靠以下评估程序。对于每个（用户、项目）复习序列，我们首先进行基于似然性的比较，并确定它在前n-1次复习，即训练复习期间，有多紧密地遵循特定的复习计划（是memorize、统一或阈值），其中n是复习序列中的复习次数。第二，我们利用最后一次复习、第n次复习或测试复习以及保留区间$t_{n-1}-t_{1}$，计算一个质量度量，即经验遗忘率$\hat{n}\left(t_{n}\right)$。第三，对于每个复习序列，我们记录质量度量的值、训练周期（即$T=t_{n-1}-t_{1}$），以及每个复习计划下的可能性。最后，我们控制训练期和复习事件的数量，并通过挑选每种方法的似然率前25%的对子来创建实验组和对照组，其中我们跳过任何位于前25%的多个方法的序列。参考SI附录第13节的额外分析，显示我们的评价程序满足实验组和对照组之间项目难度的随机分配假设（31）。

在上述过程中，为了进行基于似然的比较，我们首先要进行利用Duolingo数据集上的半衰期回归估计参数α和β以及初始遗忘率ni(0)。这里需要注意的是，我们为所有项目拟合了一组单一的参数α和β，并为每个项目i拟合了不同的初始遗忘率$n_i(0)$，我们使用幂律遗忘曲线模型，因为它在我们的实验中具有更好的性能(在MAE方面)(详见SI附录，第8节)。然后，对于每个用户，我们使用最大似然估计来拟合memorize中的参数q和统一复习时间表中的参数μ。对于基于阈值的时间表，我们对每个复习事件序列拟合一组参数c和ζ，对参数c使用最大似然估计，对参数ζ使用网格搜索，我们对每个用户使用网格搜索拟合一个参数mth。最后，我们计算每个 (user, item) 对的n-1个复习事件的时间在memorize给定强度下的似然，即$u(t)=q^{-1 / 2}(1-m(t))$；统一调度给定强度，即$u(t)=\mu$；基于阈值的调度给定强度，即$u(t)=\operatorname{cexp}((t-s) / \zeta)$。给定强度函数$u(t)$的一组复习事件$\{t_i\}$的似然$LL(\{t_i\})$可以按如下方式计算(16)。

![image-20210310104257362](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210310104257362.png)

关于每个复习时间表下的可能性值的经验分布的更多细节见SI附录第10节。

### 质量度量：经验遗忘率

对于每一个（用户、项目），经验遗忘率是指按最后一次复习事件的时间tn来估计遗忘率的经验值；即：

![image-20210310150844313](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210310150844313.png)

其中，$\hat{m}\left(t_{n}\right)$是经验回忆概率，它由时间$t_n$时该环节中含有词(项)i的句子正确回忆的分数组成。需要注意的是，这个经验估计值并不取决于记忆模型的具体选择，给定的复习序列，经验遗忘率越低，复习计划越有效。

此外，为了更公平地比较不同的项目，我们将每项经验遗忘率采用观察窗口$\hat{n}_{0}$开始时相应项目的平均经验初始遗忘率；即对于项目i。

![image-20210310104427222](Enhancing%20human%20learning%20via%20spaced%20repetition%20optimization.assets/image-20210310104427222.png)

其中Di ⊆D是项目i被复习的 (user, item) 对的子集。此外：$\hat{n}_{0,(u, i)}=-\log \left(\hat{m}\left(t_{(u, i), 1}\right)\right) /\left(t_{(u, i), 1}-t_{(u, i), 0}\right)$，其中$t_{(u, i), k}$为 (u, i) 对相关的复习序列中的第 k 次复习。然而，我们的结果对这个归一化步骤并不敏感，如SI附录第14节所示。

